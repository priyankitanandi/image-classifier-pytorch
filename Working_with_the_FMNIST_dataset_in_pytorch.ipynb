{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gXmCHcwKs6rd"
   },
   "source": [
    "# Description\n",
    "\n",
    "The Fashion MNIST dataset is made up of images from fashion chain: Zalando. It contains a training set of 60,000 images, and a test set of 10,000 images. Each image is a 28 x 28 gray scale image associated with the label from 10 classes. Each training and test example is assigned to one of the following labels. Label zero refers to a T-shirt. Label one is a trouser, and so on.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "Train a neural network model so that it can distinguish between the different classes of objects. What do the different images in the dataset look like? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PzCCniVwNTdp"
   },
   "outputs": [],
   "source": [
    "# Setting seeds to try and ensure we have the same results - this is not guaranteed across PyTorch releases.\n",
    "import torch\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PCJzXv0OK1Bs"
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "mean, std = (0.5,), (0.5,)\n",
    "\n",
    "# Create a transform and normalise data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean, std)\n",
    "                              ])\n",
    "\n",
    "# Download FMNIST training dataset and load training data\n",
    "trainset = datasets.FashionMNIST('~/.pytorch/FMNIST/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Download FMNIST test dataset and load test data\n",
    "testset = datasets.FashionMNIST('~/.pytorch/FMNIST/', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rqMqFbIVrbFH"
   },
   "outputs": [],
   "source": [
    "# \n",
    "class FMNIST(nn.Module): # FMNIST is a derived class or subclass of nn.Module base class\n",
    "  def __init__(self): # define class method with first parameter as self\n",
    "    super().__init__() # make a call to the nn.Module's dunder init method\n",
    "    self.fc1 = nn.Linear(784, 128) # we start off with 784 input nodes and must be 784 because these are the number of pixels in the input image.\n",
    "    self.fc2 = nn.Linear(128,64) # We then have two hidden layers with 128 nodes and 64 nodes chosen arbitrarily \n",
    "    self.fc3 = nn.Linear(64,10) # The final output layer has 10 nodes because there are 10 classes in the dataset\n",
    "    \n",
    "  def forward(self, x): # In forward method, we are defining the exact order of the different layers\n",
    "    x = x.view(x.shape[0], -1)\n",
    "    \n",
    "    x = F.relu(self.fc1(x)) # ReLu is a non-linear activation function that allows the nodes to learn more complex structures in an image.\n",
    "\n",
    "    x = F.relu(self.fc2(x))\n",
    "    x = self.fc3(x)\n",
    "    x = F.log_softmax(x, dim=1) # to determine the actual probability for each of the individual classes \n",
    "   \n",
    "    \n",
    "    return x\n",
    "\n",
    "model = FMNIST()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oNNyI5YRZ7H1"
   },
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "num_epochs = 3 # we run only 3 epochs or runs, through the training data\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    cum_loss = 0\n",
    "\n",
    "    for images, labels in trainloader: # take a batch of images and targets from trainloader\n",
    "        optimizer.zero_grad() # zero out gradients at the start of each epoch\n",
    "        output = model(images) # forward pass: run this batch through neural network to see what predictions neural network provides\n",
    "        # calculate the loss of the neural network for that batch\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step() # update weights of the neural network\n",
    "        \n",
    "        cum_loss += loss.item()\n",
    "     \n",
    "    print(f\"Training loss: {cum_loss/len(trainloader)}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At this point, we have trained our neural network.\n",
    "# Let's see how well it does on images that it hasn't seen before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UWYw7ZOzsS8U"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "images, labels = next(iter(testloader))\n",
    "\n",
    "# You now have a choice of any 64 images to try this on. Pick any number between zero and 63 inclusive \n",
    "# because the batch of test images is 64, so pick number less than 64 and enter that number for the test image ID below. \n",
    "test_image_id = 52\n",
    "img = images[test_image_id].view(1, 784) \n",
    "\n",
    "with torch.no_grad():\n",
    "    logps = model(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kBf23XrtqrB6"
   },
   "outputs": [],
   "source": [
    "ps = torch.exp(logps)\n",
    "nps = ps.numpy()[0]\n",
    "FMNIST_labels = ['T-shirt/top','Trouser','Pullover','Dress','Coat','Sandal','Shirt','Sport Shoes','Bag','Ankle Boot']\n",
    "plt.xticks(np.arange(10),labels=FMNIST_labels,rotation='vertical')\n",
    "plt.bar(np.arange(10), nps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for test_image_id = 52 it's predicting a sandal. Let's confirm if that's the case in the next cell block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y7gY5hARpOp4"
   },
   "outputs": [],
   "source": [
    "def denormalize(tensor):\n",
    "  tensor = tensor*0.5 + 0.5\n",
    "  return tensor\n",
    "  \n",
    "img = img.view(28,-1)\n",
    "img = denormalize(img)\n",
    "plt.imshow(img,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EDtlx2QXMdLT"
   },
   "outputs": [],
   "source": [
    "# I would agree that this does look like a sandal."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "01_Working_with_the_FMNIST_dataset.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
